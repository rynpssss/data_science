{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 時系列分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本メモ（時系列分析と状態空間モデルの基礎　RとStanで学ぶ理論と実装）\n",
    "\n",
    "## 必要知識\n",
    "- データ生成過程（DGP）\n",
    "    - 今回取得できたデータは、パラレルワールドの中の1回で取得できたデータだと考える\n",
    "    - →　母集団は、パラレルワールドの全体\n",
    "    - データ生成過程とは、取得できたデータがどのような確率分布から取得できたのかを考えること\n",
    "- 時系列分析の目的：時系列モデルを推定すること\n",
    "- ホワイトノイズ\n",
    "    - 未来予測の情報がない雑音\n",
    "    - 期待値が０で、分散が一定、自己相関が０\n",
    "- ランダムウォーク\n",
    "    - iid系列の累積和\n",
    "- 構造\n",
    "    - 特徴はデータの前後に関係があること\n",
    "    - 自己相関をグラフにする　→　コレログラム\n",
    "    - 時系列データ　＝　短期の自己相関\n",
    "           ＋周期変動\n",
    "           ＋トレンド\n",
    "           ＋外因性\n",
    "           ＋ホワイトノイズ\n",
    "- 相関\n",
    "    - 自己相関：k時点前との間にある相関\n",
    "    - 偏自己相関：k-1時点との相関をなくしたk時点との相関\n",
    "                - 「1時点まででは表現できなかった残り」同士で相関をとる\n",
    "    - iid系列\n",
    "        - データが独立である条件\n",
    "        - ホワイトノイズとの違い\n",
    "            - iidは平均０とは限らない\n",
    "            - ホワイトノイズは独立のみ。iidは独立かつ同一分布\n",
    "            - iidは強定常、ホワイトノイズは弱定常\n",
    "            - 錯乱項を発生させるには、 ホワイトノイズで十分\n",
    "            - ランダムウォークのみiidを仮定（ARやMAはホワイトノイズを仮定）\n",
    "        - iid系列　　　　　→　強定常：常に同じ確率分布\n",
    "        - ホワイトノイズ　→　弱定常：時間差のみに依存\n",
    "    - 定常性\n",
    "        - 平均と自己共分散が一定であること\n",
    "    - そもそも時系列は分析しずらいので、「分析しやすいデータ」のみを扱う　→　定常性\n",
    "        - 定常過程　→　平均が一定　\n",
    "            - 基本的なデータはトレンドがあったり、季節性があったりと、ほぼ定常ではない\n",
    "        - でも定常仮定でないと分析できないので、差分をとったりして、差分系列を作る\n",
    "            - 原系列　→　非定常過程　かつ　差分系列　→　定常過程　の場合を単位根過程（1次和分過程）\n",
    "        - ランダムウォークはホワイトノイズの累積和なので非定常だが、差分を取れば定常になる\n",
    "            \n",
    "****\n",
    "            \n",
    "##  分析手法\n",
    " - Box-Jenkins法の分析手順<br>\n",
    "    Step1　：　データを分析やすいように変換<br>\n",
    "    Step2　：　データをモデル化<br>\n",
    "    Step3　：　モデルの評価<br>\n",
    "    Step4　：　モデルで予測する<br>\n",
    "\n",
    "    - ARモデル\n",
    "        - 前地点のデータと相関がある場合\n",
    "        - yt = c + φ1yt-1 + εt　c：定数　φ：係数\n",
    "        - φ > 1：過去データの影響がずっと残る\n",
    "        - φ = 1 ：ランダムウォーク\n",
    "        - φ  < 1：過去のデータの影響がほぼなくなる\n",
    "        -　常に定常ではない（|φ|<1のみ定常）\n",
    "    - MAモデル\n",
    "        - 自己相関がある場合\n",
    "        - 常に定常\n",
    "        - 反転可能性によって、「良い性質」かを判断可能\n",
    "            - 反転可能性とは、「予測誤差（ε)の大小を、過去のデータから判断できるかどうか」\n",
    "            - 反転可能性の条件　→ 特性方程式において、解の絶対値が1より大きいこと\n",
    "            - 上記を満たすと、予測誤差（ε)の大小を、過去のデータから判断できる\n",
    "            - ※εを過去データのΣで表現する事ができる為\n",
    "    - ARとMAの違い\n",
    "        - AR：過去のある時点における自分のデータ、偏自己相関に対応\n",
    "        - MA：過去の複数地点の移動平均における自分のデータ、自己相関に対応\n",
    "    - ARIMA\n",
    "        - 和分過程の場合、ARMAは使えないので、ARIMAにして差分系列にしてから使う\n",
    "    - SARIMA\n",
    "        - ARIMAに季節性を取り入れたモデル\n",
    "        - SARIMAでは、ARIMAで使った「1時点前との変化」＋「1季節前との変化」によってモデル化\n",
    "    - ARIMAX\n",
    "        - 「回帰」要素を取り入れたARIMA\n",
    "        - ダミー変数を使って、曜日や祝日の効果を組み込める\n",
    "- 分析モデルの次数の決め方\n",
    "    - ３つの作業\n",
    "        - 次数の決定：モデル選択\n",
    "        - 差分の決定：単位根検定\n",
    "        - モデルの評価\n",
    "    - 次数の決定：AICを使って、手当たり次第に評価してみる\n",
    "        - AICを使う理由：過学習を抑えるため\n",
    "    - 差分の決定：KPSS検定かADF検定\n",
    "        - KPSS\n",
    "            - 帰無仮説：単位根なし\n",
    "            - 対立仮設：単位根あり\n",
    "        - ADF\n",
    "            - 帰無仮説：単位根あり\n",
    "            - 対立仮設：単位根なし\n",
    "        - 使い分け\n",
    "            - ADF：検定回帰式に、「被説明変数のラグ項」を含める\n",
    "    - 定常性と反転可能性の確認（ARMAの場合）\n",
    "        - 定常性\n",
    "            - MA項は常に定常なため、AR項の定常性かどうかがARMAの定常性となる\n",
    "            - AR項は定常なら常に反転可能なため、MA項の反転可能かどうかがARMAの反転可能な条件となる\n",
    "    - ARIMAの次数決定アルゴリズム<br>\n",
    "        1 : KPSS検定にて、単位根の有無を調べる<br>\n",
    "        2 : 差分系列に対して、ARIMAモデルのp,q次数を手当たり次第作成<br>\n",
    "        3 : 定常性・反転可能性をチェック<br>\n",
    "        ４ : 定常性・反転可能性チェックを通った中でAICが最も低いモデルを選ぶ<br>\n",
    "    - モデル評価\n",
    "        - 残差がホワイトノイズである　→　うまくモデル化できている\n",
    "        - 残差がホワイトノイズでない　→　まだモデルに反映できる要素が残っている\n",
    "        - 残差に自己相関があるかを検定（ホワイトノイズかどうか）\n",
    "            - リュング・ボックス検定\n",
    "                - 帰無仮説：k時点までのデータが全て自己相関0\n",
    "                - 対立仮設：いずれかが０ではない\n",
    "        - 当てはめ残差が正規分布かを検定（残差は正規分布を仮定したホワイトノイズのため）\n",
    "            - ジャック・ベラ検定\n",
    "                - 帰無仮説：正規分布\n",
    "                - 対立仮設：正規分布でない\n",
    "***\n",
    "\n",
    "## 時系列分析で気をつける点\n",
    "- めも：最小二乗法では時系列データがうまくいかない理由\n",
    "    - データが独立ではない場合が多い　→　昨日の売上が今日の売上に関係している場合が多い\n",
    "- みせかけの回帰\n",
    "    - 原因は、残差に自己相関があること\n",
    "        - 最小二乗法が有効でなくなる\n",
    "    - 最小二乗法（OLS）ではなく、一般最小二乗法（GLS）を使う → Prais–Winsten法\n",
    "        - AR(1)とすると、yt = β1 + β2xt + εt\n",
    "        - 残差εから自己相関を想定した回帰式を作り、その係数からytの推定値を作る\n",
    "        - ytの推定値は残差の自己相関を取り除いているので、時系列モデルを組む\n",
    "    - ダービン・ワトソン検定\n",
    "        - 線形回帰の結果に対して、自己相関の有無を調べる\n",
    "        - 帰無仮説：自己相関０\n",
    "        - 対立仮設：０ではない\n",
    "    - 防ぐ方法\n",
    "        - 過去のデータをモデルに組み込み、データの持つ自己相関を表現するモデルを作成（ARIMAXやVAR）\n",
    "        - 差分系列の回帰分析をとる\n",
    "            - 共和分\n",
    "                - 以下を満たす\n",
    "                    - 2つのデータどちらも単位根過程\n",
    "                    - 2つのデータは線形結合すると単位根過程でなくなる\n",
    "- VAR\n",
    "    - 多変量の時系列モデル\n",
    "        - お互いに影響を及ぼす時に考える　※どちらか一方的な場合はARIMAXを使う\n",
    "        - 例：収入と消費　→　収入が増えれば消費が増える事が仮定できる\n",
    "        - yt = c + φ1yt-1 + ... + φpyt-p + εt （t:n次ベクトル、c:n×1次定数ベクトル、φ:n×n次元係数行列）\n",
    "    - グレンジャー因果検定\n",
    "        - 相手のデータを使う事で、予測精度が上がるかどうか　→ 直接の因果ではなく、ほぼ相関に近いよう\n",
    "        - 今年の収入　＝　φ11去年の収入　＋　φ12去年の消費　＋　c + ε<br>\n",
    "          今年の収入　＝　φ21去年の収入　　　　　　　　　　　＋ c +　ε\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不明点\n",
    "### 21/12/29時点\n",
    " - 状態空間モデルとは？\n",
    " - カルマンフィルタとは？\n",
    " - 錯乱項ならホワイトノイズでも良いのに、ランダムウォークのみiidを仮定する意味は？\n",
    " - 差分を決める際に、KPSSとADFの両検定における違いは？\n",
    " - 時系列モデルで、実装している例ってある？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 関係性\n",
    "### 21/12/29時点\n",
    " - ARとVRの違い<br>\n",
    "     - AR：過去の自分と関係性がある\n",
    "     - MA：自己相関がある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
