{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 時系列分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本メモ（時系列分析と状態空間モデルの基礎　RとStanで学ぶ理論と実装）\n",
    "\n",
    "## 必要知識\n",
    "- データ生成過程（DGP）\n",
    "    - 今回取得できたデータは、パラレルワールドの中の1回で取得できたデータだと考える\n",
    "    - →　母集団は、パラレルワールドの全体\n",
    "    - データ生成過程とは、取得できたデータがどのような確率分布から取得できたのかを考えること\n",
    "- 時系列分析の目的：時系列モデルを推定すること\n",
    "- ホワイトノイズ\n",
    "    - 未来予測の情報がない雑音\n",
    "    - 期待値が０で、分散が一定、自己相関が０\n",
    "- ランダムウォーク\n",
    "    - iid系列の累積和\n",
    "- 構造\n",
    "    - 特徴はデータの前後に関係があること\n",
    "    - 自己相関をグラフにする　→　コレログラム\n",
    "    - 時系列データ　＝　短期の自己相関\n",
    "           ＋周期変動\n",
    "           ＋トレンド\n",
    "           ＋外因性\n",
    "           ＋ホワイトノイズ\n",
    "- 相関\n",
    "    - 自己相関：k時点前との間にある相関\n",
    "    - 偏自己相関：k-1時点との相関をなくしたk時点との相関\n",
    "                - 「1時点まででは表現できなかった残り」同士で相関をとる\n",
    "    - iid系列\n",
    "        - データが独立である条件\n",
    "        - ホワイトノイズとの違い\n",
    "            - iidは平均０とは限らない\n",
    "            - ホワイトノイズは独立のみ。iidは独立かつ同一分布\n",
    "            - iidは強定常、ホワイトノイズは弱定常\n",
    "            - 錯乱項を発生させるには、 ホワイトノイズで十分\n",
    "            - ランダムウォークのみiidを仮定（ARやMAはホワイトノイズを仮定）\n",
    "        - iid系列　　　　　→　強定常：常に同じ確率分布\n",
    "        - ホワイトノイズ　→　弱定常：時間差のみに依存\n",
    "    - 定常性\n",
    "        - 平均と自己共分散が一定であること\n",
    "    - そもそも時系列は分析しずらいので、「分析しやすいデータ」のみを扱う　→　定常性\n",
    "        - 定常過程　→　平均が一定　\n",
    "            - 基本的なデータはトレンドがあったり、季節性があったりと、ほぼ定常ではない\n",
    "        - でも定常仮定でないと分析できないので、差分をとったりして、差分系列を作る\n",
    "            - 原系列　→　非定常過程　かつ　差分系列　→　定常過程　の場合を単位根過程（1次和分過程）\n",
    "        - ランダムウォークはホワイトノイズの累積和なので非定常だが、差分を取れば定常になる\n",
    "            \n",
    "****\n",
    "            \n",
    "##  分析手法\n",
    " - Box-Jenkins法の分析手順<br>\n",
    "    Step1　：　データを分析やすいように変換<br>\n",
    "    Step2　：　データをモデル化<br>\n",
    "    Step3　：　モデルの評価<br>\n",
    "    Step4　：　モデルで予測する<br>\n",
    "\n",
    "    - ARモデル\n",
    "        - 前地点のデータと相関がある場合\n",
    "        - yt = c + φ1yt-1 + εt　c：定数　φ：係数\n",
    "        - φ > 1：過去データの影響がずっと残る\n",
    "        - φ = 1 ：ランダムウォーク\n",
    "        - φ  < 1：過去のデータの影響がほぼなくなる\n",
    "        -　常に定常ではない（|φ|<1のみ定常）\n",
    "    - MAモデル\n",
    "        - 自己相関がある場合\n",
    "        - 常に定常\n",
    "        - 反転可能性によって、「良い性質」かを判断可能\n",
    "            - 反転可能性とは、「予測誤差（ε)の大小を、過去のデータから判断できるかどうか」\n",
    "            - 反転可能性の条件　→ 特性方程式において、解の絶対値が1より大きいこと\n",
    "            - 上記を満たすと、予測誤差（ε)の大小を、過去のデータから判断できる\n",
    "            - ※εを過去データのΣで表現する事ができる為\n",
    "    - ARとMAの違い\n",
    "        - AR：過去のある時点における自分のデータ、偏自己相関に対応\n",
    "        - MA：過去の複数地点の移動平均における自分のデータ、自己相関に対応\n",
    "    - ARIMA\n",
    "        - 和分過程の場合、ARMAは使えないので、ARIMAにして差分系列にしてから使う\n",
    "    - SARIMA\n",
    "        - ARIMAに季節性を取り入れたモデル\n",
    "        - SARIMAでは、ARIMAで使った「1時点前との変化」＋「1季節前との変化」によってモデル化\n",
    "    - ARIMAX\n",
    "        - 「回帰」要素を取り入れたARIMA\n",
    "        - ダミー変数を使って、曜日や祝日の効果を組み込める\n",
    "- 分析モデルの次数の決め方\n",
    "    - ３つの作業\n",
    "        - 次数の決定：モデル選択\n",
    "        - 差分の決定：単位根検定\n",
    "        - モデルの評価\n",
    "    - 次数の決定：AICを使って、手当たり次第に評価してみる\n",
    "        - AICを使う理由：過学習を抑えるため\n",
    "    - 差分の決定：KPSS検定かADF検定\n",
    "        - KPSS\n",
    "            - 帰無仮説：単位根なし\n",
    "            - 対立仮設：単位根あり\n",
    "        - ADF\n",
    "            - 帰無仮説：単位根あり\n",
    "            - 対立仮設：単位根なし\n",
    "        - 使い分け\n",
    "            - ADF：検定回帰式に、「被説明変数のラグ項」を含める\n",
    "    - 定常性と反転可能性の確認（ARMAの場合）\n",
    "        - 定常性\n",
    "            - MA項は常に定常なため、AR項の定常性かどうかがARMAの定常性となる\n",
    "            - AR項は定常なら常に反転可能なため、MA項の反転可能かどうかがARMAの反転可能な条件となる\n",
    "    - ARIMAの次数決定アルゴリズム<br>\n",
    "        1 : KPSS検定にて、単位根の有無を調べる<br>\n",
    "        2 : 差分系列に対して、ARIMAモデルのp,q次数を手当たり次第作成<br>\n",
    "        3 : 定常性・反転可能性をチェック<br>\n",
    "        ４ : 定常性・反転可能性チェックを通った中でAICが最も低いモデルを選ぶ<br>\n",
    "    - モデル評価\n",
    "        - 残差がホワイトノイズである　→　うまくモデル化できている\n",
    "        - 残差がホワイトノイズでない　→　まだモデルに反映できる要素が残っている\n",
    "        - 残差に自己相関があるかを検定（ホワイトノイズかどうか）\n",
    "            - リュング・ボックス検定\n",
    "                - 帰無仮説：k時点までのデータが全て自己相関0\n",
    "                - 対立仮設：いずれかが０ではない\n",
    "        - 当てはめ残差が正規分布かを検定（残差は正規分布を仮定したホワイトノイズのため）\n",
    "            - ジャック・ベラ検定\n",
    "                - 帰無仮説：正規分布\n",
    "                - 対立仮設：正規分布でない\n",
    "***\n",
    "\n",
    "## 時系列分析で気をつける点\n",
    "- めも：最小二乗法では時系列データがうまくいかない理由\n",
    "    - データが独立ではない場合が多い　→　昨日の売上が今日の売上に関係している場合が多い\n",
    "- みせかけの回帰\n",
    "    - 原因は、残差に自己相関があること\n",
    "        - 最小二乗法が有効でなくなる\n",
    "    - 最小二乗法（OLS）ではなく、一般最小二乗法（GLS）を使う → Prais–Winsten法\n",
    "        - AR(1)とすると、yt = β1 + β2xt + εt\n",
    "        - 残差εから自己相関を想定した回帰式を作り、その係数からytの推定値を作る\n",
    "        - ytの推定値は残差の自己相関を取り除いているので、時系列モデルを組む\n",
    "    - ダービン・ワトソン検定\n",
    "        - 線形回帰の結果に対して、自己相関の有無を調べる\n",
    "        - 帰無仮説：自己相関０\n",
    "        - 対立仮設：０ではない\n",
    "    - 防ぐ方法\n",
    "        - 過去のデータをモデルに組み込み、データの持つ自己相関を表現するモデルを作成（ARIMAXやVAR）\n",
    "        - 差分系列の回帰分析をとる\n",
    "            - 共和分\n",
    "                - 以下を満たす\n",
    "                    - 2つのデータどちらも単位根過程\n",
    "                    - 2つのデータは線形結合すると単位根過程でなくなる\n",
    "- VAR\n",
    "    - 多変量の時系列モデル\n",
    "        - お互いに影響を及ぼす時に考える　※どちらか一方的な場合はARIMAXを使う\n",
    "        - 例：収入と消費　→　収入が増えれば消費が増える事が仮定できる\n",
    "        - yt = c + φ1yt-1 + ... + φpyt-p + εt （t:n次ベクトル、c:n×1次定数ベクトル、φ:n×n次元係数行列）\n",
    "    - グレンジャー因果検定\n",
    "        - 相手のデータを使う事で、予測精度が上がるかどうか　→ 直接の因果ではなく、ほぼ相関に近いよう\n",
    "        - 今年の収入　＝　φ11去年の収入　＋　φ12去年の消費　＋　c + ε<br>\n",
    "          今年の収入　＝　φ21去年の収入　　　　　　　　　　　＋ c +　ε\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARCH / GARCH\n",
    "    - 目的：時間によって、分散が変動するデータを表現するモデル\n",
    "    - 基本は、ファイナンスデータで使われる。\n",
    "    - 分散が分かれば、どれだけブレ幅があるのかが分かるので、最大でどの程度の損をするのかが分かる\n",
    "\n",
    "### 4部　状態空間モデル\n",
    "    特徴\n",
    "    - モデルの自由度が高い\n",
    "    - 自動化が困難\n",
    "    - Box-Jenkins法の比べて、属人性が高い\n",
    "\n",
    "#### 1章　状態空間モデルとは？\n",
    "    メリット\n",
    "    - 知見や感覚をモデル化可能\n",
    "    - モデルの解釈が簡単\n",
    "    - 差分をとる等の前処理が不要\n",
    "    - 欠損値があってもそのまま分析できる\n",
    "    デメリット\n",
    "    - 分析ルールが決まっていない\n",
    "\n",
    "「モデルのデータ表現」と「パラメタ推定」を分けて考えることが重要<br>\n",
    "→　「パラメタ推定」はパッケージで最悪なんとかなるが、「モデルのデータ表現」は必ず自分で組む必要がある\n",
    "\n",
    "\n",
    "モデルのデータ表現<br>\n",
    "「状態方程式」と「観測方程式」で表される<br>\n",
    "状態方程式：状態の変化のプロセスを記述　→　前時点の状態を用いた予測値＋過程誤差<br>\n",
    "観測方程式：状態から観測値が得られるプロセスを記述　→　状態　＋　観測誤差\n",
    "\n",
    "パラメタ推定<br>\n",
    "最も有名なパラメタ推定は、カルマンフィルタ＋最尤法<br>\n",
    "カルマンフィルタ：目に見えない「状態」を効率よく推定<br>\n",
    "最尤法：パラメタの推定\n",
    "→　状態とパラメタの推定に分かれている"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5部　状態空間モデルとカルマンフィルタ\n",
    "状態方程式： x t = T t * x t-1 + R δt　（δ ~ N(0,Qt)）<br>\n",
    "観測方程式：y t = Z t * x t + ε　（ε ~ N(0,Ht)）\n",
    "\n",
    "#### 状態方程式と観測方程式における推定の流れ\n",
    "1. 状態方程式から、過去の状態を用いて未来の状態を予測　→　未来の観測を予測\n",
    "2. 実際の観測値から、予測した未来の状態を補正\n",
    "3. 未来の状態から、再度未来の観測値を予測\n",
    "\n",
    "#### 平滑化\n",
    "全てのデータが手に入ったあとで、状態の補正を行う\n",
    "過去の状態を、過去の観測値と未来の観測値を使って補正する\n",
    "\n",
    "#### 最尤法\n",
    "状態の過程誤差と観測の観測誤差というパラメタを最尤法で推定\n",
    "\n",
    "#### 線形ガウス状態空間モデル（カルマンフィルタで作った状態空間モデル）の推定の流れ\n",
    "※誤差が正規分布に従っていることを仮定したモデル<br>\n",
    "1. 状態方程式・観測方程式を用いてモデルを表現\n",
    "2. 「とりあえず」のパラメタを使ってフィルタリング（状態の補正）\n",
    "3. カルマンフィルタの結果を援用し、最尤法を用いてパラメタを推定\n",
    "4. 推定されたパラメタを用いて、再度フィルタリング\n",
    "5. 推定されたパラメタを用いて、平滑化\n",
    "\n",
    "#### 2章　状態方程式・観測方程式による表現技法\n",
    "状態空間モデルは、トレンドや季節性を表現できる\n",
    "\n",
    "線形回帰を状態方程式・観測方程式すると？<br>\n",
    "線形回帰（切片のみの場合）： yt = α + vt　vt ~ N(0,σ)<br>\n",
    "↓　書き換えると<br>\n",
    "状態方程式：xt = α<br>\n",
    "観測方程式：yt = xt + vt vt ~ N(0,σ)<br>\n",
    "つまり、状態は一定で、観測誤差の分散だけがある\n",
    "\n",
    "#### ローカルレベルモデル\n",
    "過程誤差と観測誤差を両方認めた比較的簡単なモデル<br>\n",
    "状態方程式：xt = xt-1 + εt　ε ~ N(0,σ）<br>\n",
    "観測方程式：yt = xt + δt  δ ~N(0,σ）<br>\n",
    "状態方程式から、ホワイトノイズの累積和＝ランダムウォーク<br>\n",
    "観測方程式は、ランダムウォークに観測誤差を加えたデータ<br>\n",
    "→　状態空間モデルで、非定常過程（ランダムウォーク）を表現できた！！！<br>\n",
    "→　ただし、過程誤差と観測誤差の期待値が０のため、ローカルレベルモデルの期待値が一定になる。<br>\n",
    "　　→　役立たない・・・www\n",
    "\n",
    "#### ローカル線形トレンドモデル\n",
    "ローカルレベルモデルに、トレンド成分を追加したモデル<br>\n",
    "トレンド：δt = δt-1 + 残差　残差 ~ N(0,σ）<br>\n",
    "状態方程式：xt = xt-1 + δt-1 + 残差　残差 ~ N(0,σ2)<br>\n",
    "観測方程式：yt = xt + 残差　残差 ~ N(0,σ3)<br>\n",
    "\n",
    "多次元への拡張は、いつも通り行列に置き換えることで可能<br>\n",
    "線形ガウス状態空間モデルを行列表現すれば、ローカルレベルモデルもローカル線形トレンドモデルも表現可能\n",
    "\n",
    "\n",
    "#### 周期的変動モデル\n",
    "季節性の周期変動をモデル化するのは2通り<br>\n",
    "- ダミー変数を使う\n",
    "- 三角関数を使う\n",
    "\n",
    "ダミー変数を使う<br>\n",
    "x1,t = -x1,t-1 -x2,t-1 -x3,t-1 + 残差　残差 ~ N(0,σ)<br>\n",
    "x2,t = x1,t-1<br>\n",
    "x3,t = x2,t-1<br>\n",
    "yt = x1,t + 残差　残差 ~ N(0,σ1）<br>\n",
    "\n",
    "#### 基本構造時系列モデル\n",
    "時系列データ　＝　トレンド　＋　周期変動　＋　ホワイトノイズ<br>\n",
    "といった、モデルを状態空間モデルで表すと、<br>\n",
    "yt = xt + γt + ε　ε ~ N(0,σ）<br>\n",
    "となり、差分をとって・・・といったことを気にしなくてもよくなる<br>\n",
    "ARIMAXと同じように、外生変数を組み込むことも可能<br>\n",
    "\n",
    "#### 3章　カルマンフィルタ\n",
    "カルマンフィルタ：「状態の１期先への予測」と「観測値を用いた状態の補正」を繰り返して、パラメータを推定する方法<br>\n",
    "「観測値を用いた状態の補正」は以下でおこなう<br>\n",
    "補正後の状態　＝　補正前の状態　＋　カルマンゲイン（実際の観測値　ー　予測の観測値）<br>\n",
    "カルマンゲインは常に１以下<br>\n",
    "\n",
    "カルマンゲイン　＝　状態の予測誤差の分散　/　（状態の予測誤差の分散＋観測誤差の分散）<br>\n",
    "\n",
    "#### 4章　散漫カルマンフィルタ\n",
    "カルマンフィルタの弱点　→　初期値パラメータに結果が依存する<br>\n",
    "そこで、散漫初期化という手法をとる<br>\n",
    "アイデア<br>\n",
    "- 状態の初期値は分からないので諦める\n",
    "- その代わり、「状態の予測誤差の分散」の初期値を∞にする\n",
    "\n",
    "#### 5章　平滑化（スムージング）\n",
    "考え方<br>\n",
    "今日のデータを使って、今日のデータを補正　→　フィルタリング<br>\n",
    "今日のデータを使って、昨日より前のデータを補正　→　平滑化<br>\n",
    "\n",
    "移動平均をとったような、滑らかなデータになる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6部　状態空間モデルとベイズ推論\n",
    "非線形かつ非正規分布の状態空間モデルを設定する\n",
    "\n",
    "結局、GLMMのMCMCを使ったパラメータ推定と同じく、<br>\n",
    "パラメータを積分して推定することが難しいのでモンテカルロ法を使って推定を行う\n",
    "\n",
    "#### 1章　一般化状態空間モデルとベイズ推論\n",
    "データの傾向が「想像」できるときに使うモデル<br>\n",
    "ex.生物数の上限があれば、データの上限もあることが予測される。\n",
    "\n",
    "モデルが複雑になりがちだから、最尤法ではなく、MCMC（HMC法）とベイズ推論を使用して、パラメータを推定する<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不明点\n",
    "### 21/12/29時点\n",
    " - 状態空間モデルとは？\n",
    " - カルマンフィルタとは？\n",
    " - 錯乱項ならホワイトノイズでも良いのに、ランダムウォークのみiidを仮定する意味は？\n",
    " - 差分を決める際に、KPSSとADFの両検定における違いは？\n",
    " - 時系列モデルで、実装している例ってある？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 関係性\n",
    "### 21/12/29時点\n",
    " - ARとVRの違い<br>\n",
    "     - AR：過去の自分と関係性がある\n",
    "     - MA：自己相関がある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
