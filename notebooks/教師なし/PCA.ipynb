{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA（主成分分析）\n",
    "- 目的\n",
    "   - 情報（分散）をなるべく失わずに圧縮したい\n",
    "   - 相関関係がある列を少ない列数で表せる　※次元数を減らせる\n",
    "   - 大量のデータから要約できる情報を新しく作成したい\n",
    "- 求め方\n",
    "\t- x　データベクトル\n",
    "\t- １：係数を付けたw1ベクトルの合計をとる\n",
    "\t\t- w1=1で、分散が最大になるw1ベクトルを探す\n",
    "\t- ２：w2=1で、分散が最大になるw2ベクトルを探す　※　w2 とw1は直行（別種類の情報）\n",
    "\t- ・・・・（1,2のように3,4,,,と繰り返す）\n",
    "\t- z = wx\n",
    "    - 分散共分散行列の固有値問題を解く\n",
    "        - 単位ベクトル上で、主成分の行列を分散の最大化\n",
    "        - つまり、ある条件下での関数最大化（ラグランジュの未定乗数）をする\n",
    "- まとめ\n",
    "\t- 第k主成分は、k番目にばらつきが大きい方向\n",
    "\t- また、zからxへの回帰分析の残差が最小（最も情報を持っている）\n",
    "\t- 各主成分同士は相関０（直行するから）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCAと因子分析の違い\n",
    "- 結果は似ているが、行う思想が異なり、発展も違う\n",
    "- 行っていること\n",
    "    - 因子分析：因子から線形写像して、誤差が最小になる因子行列を探す\n",
    "    - 主成分分析：データから線形写像して、元データからの誤差が最小になる（分散が最大）行列を探す\n",
    "    - やっていることがそもそも似ている\n",
    "\n",
    "結果として、思想が異なる\n",
    "- 因子分析：相関を用いて、背後の構造知る　→　データの特徴を理解するために行う\n",
    "- 主成分分析：相関を用いて、情報を圧縮する　→　データの次元を下げて、使いやすいように加工する\n",
    "\n",
    "そして、発展が異なる\n",
    "- 因子分析\n",
    "    - 構造方程式\n",
    "    - 階層ベイズ\n",
    "    - グラフィカルモデル\n",
    "    - 因果推論\n",
    "- 主成分分析\n",
    "    - auto encoder\n",
    "    - 単語分散表現\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
