{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クラスタリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 階層的クラスタリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- メリット\n",
    "\t- あらかじめクラスター数を決めなくて良い\n",
    "\t- 後から、決められる\n",
    "- デメリット\n",
    "\t- 分類数が多くなると、解釈がしずらい\n",
    "\t- 計算量が多い\n",
    "\n",
    "\n",
    "- クラスタリング時に起こる現象\n",
    "    - 拡散現象：クラスタ同士が離れる\n",
    "    - 鎖効果：クラスタにデータが1つずつ吸収されること\n",
    "    \n",
    "    \n",
    "- クラスタリング手法\n",
    "    - 最近隣法（鎖効果になる）\n",
    "        - サンプル間の最も近い距離\n",
    "    - 最遠隣法（外れ値に弱いので、拡散現象になる）\n",
    "        - サンプル間の最も遠い距離\n",
    "    - 重心法\n",
    "        - 各クラスター間の重心の距離を計算\n",
    "    - 群平均法（鎖効果も拡散現象も起きずらい）\n",
    "        - クラスター同士の全データ間距離の平均\n",
    "        - ウォード法の次に分類制度が高く計算量がつくないため、計算負荷を抑えつつ分類も行いたい時に有効\n",
    "    - ウォード法（鎖効果も拡散現象も起きずらい）\n",
    "        - クラスタ内の分散を最小化しようとする\n",
    "        -  (移動後の重心と各データとの差）の二乗　 ー　（元の重心と各データとの差） の二条和\n",
    "        - 最も分類制度が高いが、計算量が多い"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 導出\n",
    "    - 重心法を繰り返す\n",
    "    - 初期値への依存で結果が異なる\n",
    "    - 距離はデータの特徴から自分で決める必要がある\n",
    "    - 何度か初期値を変えて行い、クラスタ内平方和の最小値をとる。→　クラスタ内のデータのばらつきが少ない　→　うまくクラスタリングできている\n",
    "    - エルボー法でクラスタ数を決めるのもあり\n",
    "    - 一概にどれが正解という指標がないので、色々と試していくしかないよう・・・（使いにくいな・・・）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### クラスタリングに使用する距離計算方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ユークリッド：円のように距離をとる\n",
    "\t- 一般的な距離\n",
    "- マハラノビス：データの相関を考慮した距離\n",
    "\t- 相関がある距離同士は同じ互いに異なる方向に同じだけ離れていても同じ距離とみなす（実際よりも短い距離とみなす）\n",
    "\t- 相関係数を考慮した距離\n",
    "\t- 基本的に、楕円のような距離となるので、相関が強いデータの方が距離が短い\n",
    "- マンハッタン：絶対値をとった距離\n",
    "\t- データの周りを正方形に囲む\n",
    "\t- 道路の計測を図る時に使う\n",
    "- チェビシェフ距離：絶対値の最大値\n",
    "\t- ノイズ的な特徴量の影響を抑えたい時に使用\n",
    "\t- データ間の距離が遠い＝重要なデータである場合が多く、小さい特徴量のデータ間距離を無視したい時に使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- クラスタ数の決め方は？\n",
    "    - エルボー法\n",
    "        - SSE：クラスタの重心から各点までの距離の総和\n",
    "        - これが、小さい方がうまくクラスタリング出来ているという発想\n",
    "- 次元数がめちゃくちゃ多い場合のクラスタするには？\n",
    "    - PCA　→　Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
