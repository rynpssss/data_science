{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Kmeansとの違い\n",
    "    - ハードクラスタリングとソフトクラスタリング\n",
    "    - Kmeansが距離によるクラスタリングに対して、潜在変数のディレクレ分布を推定\n",
    "- 理論\n",
    "    - 単語では見えない背後にある意味を分類する\n",
    "    - 単語ごとに各潜在変数を背後に持っていて、その潜在変数の値が同じ場合に同じトピックに属する\n",
    "    - 単語出現確率は、POSでいうところの1回の買い物で買う確率\n",
    "    - ディリクレ分布を用いて、潜在トピック座標上に次元圧縮している\n",
    "    - アイデア\n",
    "        - 文書におけるトピックの確率分布　→　ディリクレ分布　αパラメータ\n",
    "        - トピックにおける生成される単語の確率分布　→　ディリクレ分布　βパラメータ\n",
    "        - 上記を使って、潜在変数を推定していく\n",
    "- 共役事前分布\n",
    "    - メリット：ベイズ推定は事後分布の式が複雑になりがちだが、共役事前分布によって式自体は変わらないため、計算が楽\n",
    "            - 一方で、最近のベイズ推定では、 MCMCでベイズ推定が簡単に行えるようにもなってきている。\n",
    "    - 事前確率と事後確率で変化がない分布\n",
    "    - ディリクレ分布のパラメータα\n",
    "        - データを観測する前の潜在変数の仮想的頻度\n",
    "        - 単語の出現確率で例えると、単語の出現確率の偏りを表す\n",
    "        - αは大きくすると、ざっくりとしたトピックになり、\n",
    "        - αを小さくすると、詳細なトピックになる\n",
    "            - 理由は、ディリクレ分布のパラメータであり、単語の偏りを表しているため\n",
    "            - αを小さくする　→　単語郡の周辺に集まる　→　意味度合いが強い単語が集まる　→　詳細なトピック\n",
    "            - αを大きくする　→　単語郡の中心に集まる　→　意味が強くなく単語が集まる　→　ざっくりとしたトピック\n",
    "        - αが全て同じ場合と、異なる場合で性質が違う\n",
    "            - αは非対称の方が解釈性という意味においても精度が高い\n",
    "            - よりちゃんとしたαを知るためには、事後分布のパラメータを周辺化した周辺対数尤度におけるα,βの最適化が必要　→　経験ベイズ\n",
    "- 学習アルゴリズム\n",
    "    - カルバックライブラー情報量（相対エントロピー）\n",
    "        - 統計モデルの分布の近さを表す\n",
    "        - 一様分布からエントロピーがどの程度離れているのかの指標（一様分布に従う時、最大）\n",
    "    - ベイズ推定とMAP推定の違い\n",
    "        - 推定後の結果\n",
    "            - MAP推定は、最大事後確率をとってくるため点推定\n",
    "            - ベイズ推定は、事後確率を全部使うため確率分布\n",
    "        - ベイズ推定は、確率分布が出てからギブスサンプリング等をする必要がある　※積分できない複雑な式のため\n",
    "    - ベイズ推定から出た事後分布を使って、サンプリングしてパラメータを予測する方法\n",
    "        - 変分ベイズ\n",
    "            - アイデア　\n",
    "                - 今の事後分布は複雑すぎるので、別の確率分布を使って推定するように考える　※出来るだけ似ている分布\n",
    "                - →　カルバックライブラー推定方を使う　→　分布が近いかどうかの指標\n",
    "                - 別の確率分布も計算が難しいので、変分下限（周辺対数尤度）を最大化させる\n",
    "        - ギブスサンプリング\n",
    "            - 条件付き確率分布を使って、確率変数を交互にサンプル生成し、目的の事後分布をサンプル生成する\n",
    "        - 周辺化ギブスサプリング\n",
    "            - 実装が簡単\n",
    "            - アイデア\n",
    "                - ギブスサンプリングでは、パラメータのサンプリング　→　求めたい確率のサンプリングを行った。\n",
    "                - より簡単にするために、パラメータを積分消去してからサンプリング\n",
    "                - 確率変数を積分消去するため、周辺化という\n",
    "                - ※通常は積分計算が難しいが、パラメータの確率変数に共役事前分布を用いているので問題なし！\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測性能\n",
    "### パープレシキティ：予測性能\n",
    "- 確率の逆数　→　0.01なら、100個の中から正解が1つあるイメージ\n",
    "- 理論\n",
    "\t- データの次に入る単語は、文章の成り立ちからある程度推測がつく（名詞 or 動詞）\n",
    "\t- 単語は「入る」か「入らない」ではなく、「確率」で表す\n",
    "\t- perplexity = 1 /P(正解 | M)\n",
    "\t- モデルMの中で、正解語を選ぶ難しさを表す\n",
    "\t\t- →　候補数が少ないほど正解数を当てやすい　→　予測性能\n",
    "### コヒーレンス：トピックの品質\n",
    "- 指標はたくさんあるが、u_massを使用\n",
    "- トピック自体の分かりやすさを求める\n",
    "- トピックの頻出単語の共起性が高いほど、コヒーレンスも高くなる\n",
    "\t- →　トピックの特性がよりよくわかるので、人間が理解しやすくなる？\n",
    "- 各トピックのコヒーレンスの平均がコヒーレンスになる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## チューニング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BoW\n",
    "\t- レシート単位の購買アイテム　※　同じアイテムが複数出現等は、商品によって偏りが大きい\n",
    "- α\n",
    "\t- 単語ごとの特徴をより捉えたい　→　小さく設定\n",
    "- η\n",
    "\t- ？？？　→　とりあえずデフォルト？\n",
    "- トピック数\n",
    "\t- perplexity / coherenceと解釈できるこちらの限界トピック数を元に判断　→　15 - 30の間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
